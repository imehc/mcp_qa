"""
MCP UIä¸»åº”ç”¨æ–‡ä»¶
æ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„äº¤äº’ç•Œé¢
"""

import asyncio
import time
from pathlib import Path
from typing import List, Dict, Any
import chainlit as cl
from chainlit.types import AskFileResponse
import aiofiles

from .clients import unified_mcp_client, unified_model_client
from .clients.client_manager import initialize_all_clients
from .config import UIConfig, SystemPrompts
from .handlers import command_registry
from .utils import get_logger, ui_logger

logger = get_logger(__name__)

@cl.on_chat_start
async def on_chat_start():
    """èŠå¤©å¼€å§‹æ—¶çš„åˆå§‹åŒ–"""
    
    logger.info("ç”¨æˆ·å¼€å§‹æ–°çš„èŠå¤©ä¼šè¯")
    
    # åˆå§‹åŒ–ç”¨æˆ·ä¼šè¯
    cl.user_session.set("conversation_history", [])
    cl.user_session.set("knowledge_base", {})
    cl.user_session.set("current_model", UIConfig.DEFAULT_MODEL)
    cl.user_session.set("current_provider", UIConfig.DEFAULT_PROVIDER)
    
    # åˆå§‹åŒ–æ‰€æœ‰å®¢æˆ·ç«¯
    await initialize_all_clients()
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    health_results = await unified_mcp_client.health_check_all()
    model_health = await unified_model_client.health_check_all()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æœåŠ¡
    if not any(health_results.values()):
        await cl.Message(content="âš ï¸ æ‰€æœ‰MCPæœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨").send()
        logger.warning("æ‰€æœ‰MCPæœåŠ¡å™¨è¿æ¥å¤±è´¥")
    
    if not any(model_health.values()):
        await cl.Message(content="âš ï¸ æ‰€æœ‰æ¨¡å‹æœåŠ¡è¿æ¥å¤±è´¥ï¼ŒAIåŠŸèƒ½ä¸å¯ç”¨").send()
        logger.warning("æ‰€æœ‰æ¨¡å‹æœåŠ¡è¿æ¥å¤±è´¥")
    
    # è·å–å¯ç”¨æ¨¡å‹å¹¶è®©ç”¨æˆ·é€‰æ‹©
    available_models = await unified_model_client.list_all_models()
    if available_models:
        # æ„å»ºæ¨¡å‹é€‰é¡¹
        model_options = []
        for adapter_name, models in available_models.items():
            if models:  # å¦‚æœè¯¥é€‚é…å™¨æœ‰å¯ç”¨æ¨¡å‹
                provider = unified_model_client.get_adapter(adapter_name).provider
                for model in models[:3]:  # é™åˆ¶æ¯ä¸ªæä¾›å•†æœ€å¤š3ä¸ªæ¨¡å‹
                    model_options.append(cl.SelectOption(
                        value=f"{adapter_name}:{model}",
                        label=f"{provider} - {model}"
                    ))
        
        if model_options:
            selected_model = await cl.AskSelectMessage(
                content="ğŸ¤– è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼š",
                options=model_options,
                timeout=30
            ).send()
            if selected_model:
                adapter_name, model_name = selected_model["value"].split(":", 1)
                cl.user_session.set("current_model", model_name)
                cl.user_session.set("current_adapter", adapter_name)
                logger.info(f"ç”¨æˆ·é€‰æ‹©æ¨¡å‹: {adapter_name} - {model_name}")
    
    # å‘é€æ¬¢è¿æ¶ˆæ¯
    welcome_msg = """# ğŸ¤– æ™ºèƒ½çŸ¥è¯†åº“åŠ©æ‰‹

æ¬¢è¿ä½¿ç”¨åŸºäºMCPçš„æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿï¼

## ğŸš€ åŠŸèƒ½ç‰¹æ€§
- ğŸ“ **æ–‡æ¡£è§£æ**: æ”¯æŒPDFã€Wordã€Excelã€PPTã€Markdownç­‰æ ¼å¼
- ğŸ” **è¯­ä¹‰æœç´¢**: åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½æœç´¢
- ğŸ§  **å¤šæ¨¡å‹æ”¯æŒ**: é›†æˆOllamaæœ¬åœ°æ¨¡å‹å’Œè¿œç¨‹APIæ¨¡å‹
- ğŸŒ **è¿œç¨‹MCP**: æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹MCPå·¥å…·æœåŠ¡å™¨
- ğŸ“Š **è¿‡ç¨‹å¯è§†åŒ–**: å®æ—¶å±•ç¤ºæ€è€ƒå’Œå¤„ç†è¿‡ç¨‹
- ğŸ› ï¸ **MCPå·¥å…·**: å¼ºå¤§çš„æ¨¡å—åŒ–å·¥å…·é›†

## ğŸ¯ ä½¿ç”¨æ–¹å¼
1. **ä¸Šä¼ æ–‡æ¡£**: ç‚¹å‡»ä¸Šä¼ æŒ‰é’®æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
2. **æ„å»ºç´¢å¼•**: ä½¿ç”¨ `/build` å‘½ä»¤æ„å»ºæ–‡æ¡£ç´¢å¼•
3. **æ™ºèƒ½é—®ç­”**: ç›´æ¥æé—®ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æœç´¢ç›¸å…³å†…å®¹å¹¶å›ç­”
4. **å·¥å…·è°ƒç”¨**: ä½¿ç”¨ `/help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤

## ğŸ”§ æ”¯æŒçš„æ¨¡å‹æä¾›å•†
- **Ollama**: æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹
- **OpenAI**: GPTç³»åˆ—æ¨¡å‹
- **Anthropic**: Claudeç³»åˆ—æ¨¡å‹
- **Google**: Geminiç³»åˆ—æ¨¡å‹
- **Azure**: Azure OpenAIæœåŠ¡

å¼€å§‹å¯¹è¯å§ï¼ ğŸ‰"""
    
    await cl.Message(content=welcome_msg).send()
    ui_logger.log_user_action("chat_start")

@cl.on_message
async def on_message(message: cl.Message):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    
    user_input = message.content.strip()
    ui_logger.log_user_action("send_message", {"length": len(user_input)})
    
    # å¤„ç†å‘½ä»¤
    if user_input.startswith("/"):
        await handle_command(user_input)
        return
    
    # å¤„ç†æ™®é€šé—®ç­”
    await handle_qa(user_input)

async def handle_command(command_text: str):
    """å¤„ç†å‘½ä»¤è¾“å…¥"""
    
    parts = command_text.strip().split()
    if not parts:
        return
    
    command = parts[0][1:].lower()  # ç§»é™¤ '/' å‰ç¼€
    args = parts[1:]
    
    # è·å–å‘½ä»¤å¤„ç†å™¨
    handler = command_registry.get_handler(command)
    
    if handler:
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {command} {args}")
        try:
            await handler.execute(args)
        except Exception as e:
            error_msg = f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
            await cl.Message(content=error_msg).send()
            ui_logger.log_error(e, f"æ‰§è¡Œå‘½ä»¤å¤±è´¥: {command}")
    else:
        # æœªçŸ¥å‘½ä»¤
        available_commands = command_registry.list_commands()
        error_msg = f"âŒ æœªçŸ¥å‘½ä»¤: `{command}`\n\nğŸ’¡ å¯ç”¨å‘½ä»¤: {', '.join([f'`/{cmd}`' for cmd in available_commands])}\n\nä½¿ç”¨ `/help` æŸ¥çœ‹è¯¦ç»†å¸®åŠ©ã€‚"
        await cl.Message(content=error_msg).send()

async def handle_qa(question: str):
    """å¤„ç†é—®ç­”è¯·æ±‚"""
    
    logger.info(f"å¤„ç†é—®ç­”è¯·æ±‚: {question[:100]}...")
    
    # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
    thinking_msg = cl.Message(content="ğŸ¤” æ­£åœ¨æ€è€ƒ...")
    await thinking_msg.send()
    
    start_time = time.time()
    
    try:
        # 1. æœç´¢ç›¸å…³æ–‡æ¡£
        await thinking_msg.update(content="ğŸ” æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...")
        search_result = await unified_mcp_client.search_documents(question, top_k=UIConfig.DEFAULT_SEARCH_K)
        
        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = ""
        context_sources = []
        
        if search_result.get("results"):
            await thinking_msg.update(content="ğŸ“š æ­£åœ¨åˆ†ææœç´¢ç»“æœ...")
            for doc in search_result["results"]:
                title = doc.get('title', 'æœªçŸ¥æ–‡æ¡£')
                content = doc.get('content', '')
                score = doc.get('score', 0)
                
                context += f"æ–‡æ¡£: {title}\nå†…å®¹: {content}\nç›¸å…³æ€§: {score:.3f}\n\n"
                context_sources.append({
                    "title": title,
                    "score": score,
                    "content": content[:200] + "..." if len(content) > 200 else content
                })
        
        # 3. ç”Ÿæˆå›ç­”
        await thinking_msg.update(content="ğŸ§  æ­£åœ¨ç”Ÿæˆå›ç­”...")
        
        current_adapter = cl.user_session.get("current_adapter")
        current_model = cl.user_session.get("current_model", UIConfig.DEFAULT_MODEL)
        
        # æ„å»ºæç¤ºè¯
        user_prompt = f"""é—®é¢˜: {question}

æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£:
{context if context else "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
        
        # è°ƒç”¨ç»Ÿä¸€æ¨¡å‹å®¢æˆ·ç«¯
        model_start_time = time.time()
        response = await unified_model_client.generate(
            prompt=user_prompt,
            model_name=current_adapter,
            system=SystemPrompts.QA_SYSTEM_PROMPT,
            temperature=UIConfig.TEMPERATURE,
            max_tokens=UIConfig.MAX_TOKENS
        )
        model_duration = time.time() - model_start_time
        
        # è®°å½•æ¨¡å‹è°ƒç”¨
        ui_logger.log_model_call(
            model=f"{response.provider}:{response.model}",
            prompt_length=len(user_prompt),
            response_length=len(response.content),
            duration=model_duration
        )
        
        # 4. æ„å»ºæœ€ç»ˆå›ç­”
        total_duration = time.time() - start_time
        
        final_content = f"## ğŸ’¡ å›ç­”\n\n{response.content}"
        
        # æ·»åŠ å‚è€ƒæ–‡æ¡£ä¿¡æ¯
        if context_sources:
            final_content += "\n\n## ğŸ“š å‚è€ƒæ–‡æ¡£\n\n"
            for i, source in enumerate(context_sources, 1):
                final_content += f"**{i}. {source['title']}** (ç›¸ä¼¼åº¦: {source['score']:.3f})\n"
                final_content += f"{source['content']}\n\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        final_content += f"\n---\nâ±ï¸ æ€»ç”¨æ—¶: {total_duration:.2f}ç§’ | ğŸ¤– æ¨¡å‹: {response.provider} - {response.model}"
        
        await thinking_msg.update(content=final_content)
        
        # æ›´æ–°å¯¹è¯å†å²
        history = cl.user_session.get("conversation_history", [])
        history.append({
            "question": question,
            "answer": response.content,
            "sources": context_sources,
            "timestamp": time.time(),
            "model": f"{response.provider}:{response.model}",
            "duration": total_duration
        })
        cl.user_session.set("conversation_history", history)
        
        logger.info(f"é—®ç­”å®Œæˆï¼Œç”¨æ—¶: {total_duration:.2f}ç§’")
        
    except Exception as e:
        error_msg = f"âŒ å¤„ç†é—®ç­”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        await thinking_msg.update(content=error_msg)
        ui_logger.log_error(e, "å¤„ç†é—®ç­”æ—¶å‘ç”Ÿå¼‚å¸¸")

@cl.on_file_upload
async def on_file_upload(files: List[AskFileResponse]):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
    
    logger.info(f"ç”¨æˆ·ä¸Šä¼ äº† {len(files)} ä¸ªæ–‡ä»¶")
    ui_logger.log_user_action("upload_files", {"count": len(files)})
    
    uploaded_files = []
    failed_files = []
    
    # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    upload_dir = Path(UIConfig.UPLOAD_DIR)
    upload_dir.mkdir(exist_ok=True)
    
    for file in files:
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if len(file.content) > UIConfig.MAX_FILE_SIZE:
                failed_files.append(f"{file.name} (æ–‡ä»¶è¿‡å¤§)")
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = Path(file.name).suffix.lower()
            if file_ext not in UIConfig.ALLOWED_EXTENSIONS:
                failed_files.append(f"{file.name} (æ ¼å¼ä¸æ”¯æŒ)")    
                continue
            
            # ä¿å­˜æ–‡ä»¶
            file_path = upload_dir / file.name
            async with aiofiles.open(file_path, "wb") as f:
                await f.write(file.content)
            
            uploaded_files.append(file.name)
            ui_logger.log_file_operation("upload", str(file_path), True)
            
            # è‡ªåŠ¨è§£ææ–‡æ¡£
            parse_result = await unified_mcp_client.parse_document(str(file_path))
            if "error" not in parse_result:
                logger.info(f"æ–‡æ¡£ä¸Šä¼ å¹¶è§£ææˆåŠŸ: {file.name}")
            else:
                logger.warning(f"æ–‡æ¡£ä¸Šä¼ æˆåŠŸä½†è§£æå¤±è´¥: {file.name}, é”™è¯¯: {parse_result['error']}")
                
        except Exception as e:
            failed_files.append(f"{file.name} (å¤„ç†å¤±è´¥)")
            ui_logger.log_error(e, f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {file.name}")
    
    # å‘é€ç»“æœæ¶ˆæ¯
    if uploaded_files:
        msg = f"âœ… **ä¸Šä¼ æˆåŠŸ** ({len(uploaded_files)} ä¸ªæ–‡ä»¶):\n"
        for name in uploaded_files:
            msg += f"- ğŸ“„ {name}\n"
        
        if failed_files:
            msg += f"\nâŒ **ä¸Šä¼ å¤±è´¥** ({len(failed_files)} ä¸ªæ–‡ä»¶):\n"
            for name in failed_files:
                msg += f"- âŒ {name}\n"
        
        msg += f"\nğŸ’¡ **å»ºè®®**: æ‰§è¡Œ `/build` å‘½ä»¤æ„å»ºæœç´¢ç´¢å¼•ä»¥å¯ç”¨æ™ºèƒ½é—®ç­”åŠŸèƒ½ã€‚"
        
    else:
        msg = f"âŒ æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥:\n"
        for name in failed_files:
            msg += f"- âŒ {name}\n"
        
        msg += f"\nğŸ’¡ **æç¤º**: æ”¯æŒçš„æ ¼å¼åŒ…æ‹¬ {', '.join(UIConfig.ALLOWED_EXTENSIONS)}"
    
    await cl.Message(content=msg).send()

def create_app():
    """åˆ›å»ºåº”ç”¨å®ä¾‹"""
    logger.info("åˆ›å»ºMCP UIåº”ç”¨")
    
    # éªŒè¯é…ç½®
    config_validation = UIConfig.validate_config()
    if not config_validation["valid"]:
        logger.error("é…ç½®éªŒè¯å¤±è´¥:")
        for issue in config_validation["issues"]:
            logger.error(f"  - {issue}")
        raise ValueError("é…ç½®éªŒè¯å¤±è´¥")
    
    logger.info("MCP UIåº”ç”¨åˆ›å»ºå®Œæˆ")
    return True